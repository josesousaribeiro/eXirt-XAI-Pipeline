{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kjIG882ZoyVl"
      },
      "source": [
        "Simple example of eXirt's use"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Run all bullets in the sequence below!"
      ],
      "metadata": {
        "id": "7Pzk_smLpiUR"
      }
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tM_sX-w4IcIJ"
      },
      "source": [
        "\n",
        "\n",
        "Generate files?\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "fYRB58lNnHAX"
      },
      "source": [
        "## Install dependences"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import warnings\n",
        "warnings.filterwarnings('ignore')"
      ],
      "metadata": {
        "id": "fosnazN4cyp-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install openml\n",
        "!pip install catsim\n",
        "\n",
        "import openml\n",
        "import pandas as pd\n",
        "import statistics\n",
        "import numpy as np\n",
        "import random\n",
        "import copy\n",
        "\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import GradientBoostingClassifier\n",
        "from sklearn import metrics\n",
        "from google.colab import files\n",
        "\n",
        "\n",
        "\n",
        "!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n",
        "!wget https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ySk3bH_Vm1Cn",
        "outputId": "b379ad30-3d96-47e7-e668-6939599b80a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting openml\n",
            "  Downloading openml-0.13.1.tar.gz (127 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.6/127.6 kB\u001b[0m \u001b[31m11.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting liac-arff>=2.4.0 (from openml)\n",
            "  Downloading liac-arff-2.5.0.tar.gz (13 kB)\n",
            "  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Collecting xmltodict (from openml)\n",
            "  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from openml) (2.27.1)\n",
            "Requirement already satisfied: scikit-learn>=0.18 in /usr/local/lib/python3.10/dist-packages (from openml) (1.2.2)\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.10/dist-packages (from openml) (2.8.2)\n",
            "Requirement already satisfied: pandas>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from openml) (1.5.3)\n",
            "Requirement already satisfied: scipy>=0.13.3 in /usr/local/lib/python3.10/dist-packages (from openml) (1.10.1)\n",
            "Requirement already satisfied: numpy>=1.6.2 in /usr/local/lib/python3.10/dist-packages (from openml) (1.22.4)\n",
            "Collecting minio (from openml)\n",
            "  Downloading minio-7.1.15-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.4/77.4 kB\u001b[0m \u001b[31m7.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pyarrow in /usr/local/lib/python3.10/dist-packages (from openml) (9.0.0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=1.0.0->openml) (2022.7.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil->openml) (1.16.0)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn>=0.18->openml) (3.1.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from minio->openml) (2022.12.7)\n",
            "Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from minio->openml) (1.26.15)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests->openml) (3.4)\n",
            "Building wheels for collected packages: openml, liac-arff\n",
            "  Building wheel for openml (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for openml: filename=openml-0.13.1-py3-none-any.whl size=142784 sha256=37c5add686035cb29fff159f1b1a07cf316ba353e5081d4bf7b9a0b01f3b5665\n",
            "  Stored in directory: /root/.cache/pip/wheels/f7/7a/fa/f73edc5ccecbab13bbf5fb888f2f943720f77114a1fa4ceffe\n",
            "  Building wheel for liac-arff (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for liac-arff: filename=liac_arff-2.5.0-py3-none-any.whl size=11717 sha256=5d24eee940e4ce171fcdf14a78e33ef802bd9f4318cb21d8f49738032bd7482a\n",
            "  Stored in directory: /root/.cache/pip/wheels/5d/2a/9c/3895d9617f8f49a0883ba686326d598e78a1c2f54fe3cae86d\n",
            "Successfully built openml liac-arff\n",
            "Installing collected packages: xmltodict, minio, liac-arff, openml\n",
            "Successfully installed liac-arff-2.5.0 minio-7.1.15 openml-0.13.1 xmltodict-0.13.0\n",
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting catsim\n",
            "  Downloading catsim-0.17.2-py3-none-any.whl (32 kB)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catsim) (1.10.1)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.10/dist-packages (from catsim) (2.8.4)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catsim) (3.7.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from catsim) (1.2.2)\n",
            "Collecting json-tricks (from catsim)\n",
            "  Downloading json_tricks-3.17.0-py2.py3-none-any.whl (27 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.10/dist-packages (from catsim) (4.65.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from catsim) (1.22.4)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (1.0.7)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (4.39.3)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (3.0.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catsim) (2.8.2)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->catsim) (1.2.0)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->catsim) (3.1.0)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.7->matplotlib->catsim) (1.16.0)\n",
            "Installing collected packages: json-tricks, catsim\n",
            "Successfully installed catsim-0.17.2 json-tricks-3.17.0\n",
            "--2023-05-30 00:50:01--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_MLtIRT.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 7453 (7.3K) [text/plain]\n",
            "Saving to: ‘decodIRT_MLtIRT.py’\n",
            "\n",
            "decodIRT_MLtIRT.py  100%[===================>]   7.28K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-30 00:50:01 (97.5 MB/s) - ‘decodIRT_MLtIRT.py’ saved [7453/7453]\n",
            "\n",
            "--2023-05-30 00:50:01--  https://raw.githubusercontent.com/josesousaribeiro/eXirt-XAI-Benchmark/main/decodIRT/decodIRT_analysis.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.110.133, 185.199.109.133, 185.199.108.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.110.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 33818 (33K) [text/plain]\n",
            "Saving to: ‘decodIRT_analysis.py’\n",
            "\n",
            "decodIRT_analysis.p 100%[===================>]  33.03K  --.-KB/s    in 0s      \n",
            "\n",
            "2023-05-30 00:50:01 (102 MB/s) - ‘decodIRT_analysis.py’ saved [33818/33818]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xQcwXWF97TrR"
      },
      "source": [
        "## eXirt tool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0Pvq-euegHVF"
      },
      "outputs": [],
      "source": [
        "class EXirt():\n",
        "  # -*- coding: utf-8 -*-\n",
        "  \"\"\"\n",
        "  Created on Sat Oct 18 21:21:11 2021\n",
        "  @author: Jose Ribeiro\n",
        "  This class performs all ensemble-based black box machine learning model explanation processes using advanced IRT techniques.\n",
        "\n",
        "  Link: https://github.com/josesousaribeiro/eXirt\n",
        "\n",
        "  \"\"\"\n",
        "\n",
        "  def dirByDataset(self, datasetName):\n",
        "      !mkdir $self.path_content$self.path_fig$datasetName\n",
        "      !mkdir $self.path_content$self.path_csv$datasetName\n",
        "      !mkdir $self.path_content$self.path_model$datasetName\n",
        "      !mkdir $self.path_content$self.path_irt$datasetName\n",
        "\n",
        "  def __init__(self):\n",
        "    ############################## PATH FILE ###################################\n",
        "    self.do_download = True\n",
        "\n",
        "    self.path_content = '/content'\n",
        "    self.path_fig = '/out_fig'\n",
        "    self.path_csv = '/out_csv'\n",
        "    self.path_model = '/out_model'\n",
        "    self.path_irt = '/out_irt'\n",
        "    self.path_dataset = '/*'\n",
        "\n",
        "    !rm -r $self.path_content$self.path_fig\n",
        "    !rm -r $self.path_content$self.path_csv\n",
        "    !rm -r $self.path_content$self.path_model\n",
        "    !rm -r $self.path_content$self.path_irt\n",
        "\n",
        "\n",
        "    !mkdir $self.path_content$self.path_fig\n",
        "    !mkdir $self.path_content$self.path_csv\n",
        "    !mkdir $self.path_content$self.path_model\n",
        "    !mkdir $self.path_content$self.path_irt\n",
        "\n",
        "    self.path_dataset = ''\n",
        "    ############################## GENERAL CONTROL #############################\n",
        "    self.proposal_1_pool = 1\n",
        "    self.proposal_2_loop = 2\n",
        "    self.exec_proposal = self.proposal_2_loop\n",
        "\n",
        "    # verbose\n",
        "    self.verbose = False\n",
        "    self.verbose_graph = False\n",
        "\n",
        "    self.download_files = True\n",
        "\n",
        "    # performance\n",
        "    self.exec_accuracy = 1\n",
        "    self.exec_auc = 2\n",
        "    self.exec_performance = self.exec_accuracy\n",
        "    self.normalize_performance = True\n",
        "\n",
        "    ################################### IRT ####################################\n",
        "    #execute theta ou trueScore\n",
        "    self.exec_theta = 0\n",
        "    self.exec_trueScore = 1\n",
        "    self.exec_base_irt_score = self.exec_trueScore\n",
        "\n",
        "    # calculo de  theta\n",
        "    self.theta_sum = 0\n",
        "    self.theta_min = 1\n",
        "    self.theta_mean = 2\n",
        "    self.exec_calc_theta = self.theta_mean\n",
        "\n",
        "\n",
        "    # irt algorithm ‘ternary’, ‘dichotomous’, ‘fibonacci’, ‘golden’, ‘brent’, ‘bounded’ and ‘golden2’\n",
        "    self.irt_method_fibonacci = '-metodo fibonacci'\n",
        "    self.irt_method_bounded = '-metodo bounded'\n",
        "    self.irt_method_ternary = '-metodo ternary' #long time execution\n",
        "    self.irt_method_dichotomous = '-metodo dichotomous' #long time execution\n",
        "    self.irt_method_golden = '-metodo golden'\n",
        "    self.irt_method_brent = '-metodo brent'\n",
        "    self.irt_method_golden2 = '-metodo golden2' #problem in execution\n",
        "    self.irt_method = self.irt_method_bounded\n",
        "\n",
        "    # Properties of IRT\n",
        "    self.irt_discriminate = True #False remove the property by IRTs calc.\n",
        "    self.irt_difficulty = True #False remove the property by IRTs calc.\n",
        "    self.irt_divine = True #False remove the property by IRTs calc.\n",
        "\n",
        "    ################################## PROPOSAL 1 POOL #########################\n",
        "    self.include_original_clf_data_pool = True\n",
        "    self.number_of_features_deletion = 1 # values 1 to ++\n",
        "\n",
        "    self.list_clf_pool = [] #empity\n",
        "\n",
        "    ################################## PROPOSAL 2 LOOP #########################\n",
        "\n",
        "    self.include_original_clf_data_loop = True\n",
        "    self.number_of_features_variation = 1 # values 1 to 4\n",
        "\n",
        "    # test or train\n",
        "    self.exec_test = 0\n",
        "    self.exec_train = 1\n",
        "    self.exec_in = self.exec_test\n",
        "\n",
        "    #loop of models variation\n",
        "    self.exec_permutation = 0 # random base\n",
        "    self.exec_noise = 1 # random base\n",
        "    self.exec_zeros = 2\n",
        "    self.exec_norm = 3\n",
        "    self.exec_ordup = 4\n",
        "    self.exec_orddown = 5\n",
        "    self.exec_inver = 6\n",
        "    self.exec_binning = 7\n",
        "    self.exec_mult_neg = 8\n",
        "    self.exec_mean = 9\n",
        "    self.exec_std = 10\n",
        "    self.exec_zscore = 11\n",
        "    self.exec_variation_method = [self.exec_mult_neg, self.exec_binning, self.exec_zeros, self.exec_ordup, self.exec_inver, self.exec_std, self.exec_zscore]\n",
        "\n",
        "    #list of thetas\n",
        "    self.list_clf_loop = [] #empity\n",
        "\n",
        "  ########################## Global declaration ################################\n",
        "\n",
        "  def z_score_serie(self, s):\n",
        "    # copy the dataframe\n",
        "    s_std = s.copy()\n",
        "    s_std = (s_std - s_std.mean()) / s_std.std()\n",
        "    return s_std\n",
        "\n",
        "  def auc_score(self, y, y_pred):\n",
        "\n",
        "      fpr, tpr, thresholds = metrics.roc_curve(y, y_pred, pos_label=2)\n",
        "\n",
        "      return metrics.auc(fpr, tpr)\n",
        "\n",
        "  def powerSetLimited(self, s,l):\n",
        "\n",
        "      def powerset(s):\n",
        "        x = len(s)\n",
        "        masks = [1 << i for i in range(x)]\n",
        "        for i in range(1 << x):\n",
        "            yield [ss for mask, ss in zip(masks, s) if i & mask]\n",
        "\n",
        "      psl = []\n",
        "      ps = list(powerset(s))\n",
        "      for _,i in enumerate(ps):\n",
        "        if len(i) <= l and len(i)>0:\n",
        "          psl.append(i)\n",
        "      return psl\n",
        "\n",
        "  def run_prepare(self, model,data_exec_x, data_exec_y, X_train, X_test, y_train, y_test):\n",
        "    %rm $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv'\n",
        "    %rm $self.path_content$self.path_irt'/tabela_base_para_executar_irt_accuracy.csv'\n",
        "\n",
        "    def compResponses(a,b):\n",
        "      c = []\n",
        "      for i,_ in enumerate(a):\n",
        "        if a[i] == b[i]:\n",
        "          c.append(1)\n",
        "        else:\n",
        "          c.append(0)\n",
        "      return c\n",
        "\n",
        "    #prediction\n",
        "    original_outputs = model.predict(data_exec_x)\n",
        "\n",
        "\n",
        "    #XAI-IRT\n",
        "    # train, test, model and outputs\n",
        "\n",
        "    #Loop of models\n",
        "    df_loop_of_models = pd.DataFrame()\n",
        "\n",
        "    #Prepare df_loop_of_models\n",
        "    #df_loop_of_models['Clf'] = []\n",
        "    #for i in range(len(data_exec_y)):\n",
        "    #  df_loop_of_models['V'+str(i)] = []\n",
        "\n",
        "    list_col_tmp = ['Clf']\n",
        "    for i in range(len(data_exec_y)):\n",
        "      list_col_tmp.append('V'+str(i))\n",
        "    df_loop_of_models = pd.DataFrame(columns=list_col_tmp)\n",
        "\n",
        "    df_loop_of_models_performance = pd.DataFrame(columns=['Metodo','Acuracia'])\n",
        "\n",
        "\n",
        "\n",
        "    if self.exec_proposal == self.proposal_2_loop:\n",
        "      if self.verbose:\n",
        "        print('Original data')\n",
        "        print(data_exec_x)\n",
        "\n",
        "      number_of_instances = len(data_exec_x)\n",
        "\n",
        "      if self.include_original_clf_data_loop:\n",
        "        str_tmp = 'Clf original data'\n",
        "        if self.exec_performance == self.exec_accuracy:\n",
        "          result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=self.normalize_performance) #accuracy\n",
        "        else:\n",
        "          if self.exec_performance == self.exec_auc:\n",
        "            result_accuracy = self.auc_score(original_outputs, original_outputs) #AUC\n",
        "\n",
        "        result_bin = compResponses(list(original_outputs), list(original_outputs))\n",
        "        result_bin.insert(0,str_tmp)\n",
        "        df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "        df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_tmp, result_accuracy]\n",
        "\n",
        "      #inset variation of ONE attribute in loop of models\n",
        "      if self.number_of_features_variation >= 1:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id,c in enumerate(data_exec_x.columns):\n",
        "            #criando cópia do dado inicial\n",
        "            data_exec_x_copy = data_exec_x.copy()\n",
        "            if variation == self.exec_permutation:\n",
        "              #trocando posições de cada instância do atributo da vez\n",
        "              random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "              data_exec_x_copy[c] = data_exec_x_copy[c].values[random_id]\n",
        "              method = 'Permutation'\n",
        "            else:\n",
        "              if variation == self.exec_noise:\n",
        "                #aplica ruido a cada instâcia do atributo da vez\n",
        "                noise = np.random.normal(0, 1, number_of_instances)\n",
        "                data_exec_x_copy[c] = data_exec_x_copy[c] + noise\n",
        "                method = 'Noise'\n",
        "              else:\n",
        "                if variation == self.exec_zeros:\n",
        "                  #aplica zeros a cada instância do atributo da vez\n",
        "                  zeros = np.zeros(number_of_instances)\n",
        "                  data_exec_x_copy[c] = zeros\n",
        "                  method = 'Zeros'\n",
        "                else:\n",
        "                  if variation == self.exec_norm:\n",
        "                    #normaliza os elementos\n",
        "                    norm = np.linalg.norm(data_exec_x_copy[c])\n",
        "                    normal_array = data_exec_x_copy[c]/norm\n",
        "                    data_exec_x_copy[c] = normal_array\n",
        "                    method = 'Normalization'\n",
        "                  else:\n",
        "                    if variation == self.exec_ordup:\n",
        "                      #ordena em ordem crescente os elementos\n",
        "                      order_up = np.sort(data_exec_x_copy[c])\n",
        "                      data_exec_x_copy[c] = order_up\n",
        "                      method = 'Ordernation_Up'\n",
        "                    else:\n",
        "                      if variation == self.exec_orddown:\n",
        "                        #ordena em ordem decrescente os elementos\n",
        "                        order_down = -np.sort(-data_exec_x_copy[c])\n",
        "                        data_exec_x_copy[c] = order_down\n",
        "                        method = 'Ordernation_Down'\n",
        "                      else:\n",
        "                        if variation == self.exec_inver:\n",
        "                          #inverte os elementos\n",
        "                          transp = np.flipud(data_exec_x_copy[c])\n",
        "                          data_exec_x_copy[c] = transp\n",
        "                          method = 'Invertion'\n",
        "                        else:\n",
        "                          if variation == self.exec_binning:\n",
        "                            #inverte os elementos\n",
        "                            mean_arr = np.mean(data_exec_x_copy[c])\n",
        "                            binn = np.digitize(data_exec_x_copy[c],bins=[mean_arr])\n",
        "                            data_exec_x_copy[c] = binn\n",
        "                            method = 'Binning'\n",
        "                          else:\n",
        "                            if variation == self.exec_mult_neg:\n",
        "                              #multiplica por -1\n",
        "                              data_exec_x_copy[c] = data_exec_x_copy[c] * -1\n",
        "                              method = 'MultNeg'\n",
        "                            else:\n",
        "                              if variation == self.exec_mean:\n",
        "                                #mean\n",
        "                                inst =  len(data_exec_x_copy[c])\n",
        "                                data_exec_x_copy[c] = [statistics.mean(data_exec_x_copy[c])]*inst\n",
        "                                method = 'Mean'\n",
        "                              else:\n",
        "                                if variation == self.exec_std:\n",
        "                                  #std\n",
        "                                  inst =  len(data_exec_x_copy[c])\n",
        "                                  data_exec_x_copy[c] = [statistics.stdev(data_exec_x_copy[c])]*inst\n",
        "                                  method = 'Std'\n",
        "                                else:\n",
        "                                  if variation == self.exec_zscore:\n",
        "                                    #zscore\n",
        "                                    data_exec_x_copy[c] = self.z_score_serie(data_exec_x_copy[c])\n",
        "                                    method = 'Zscore'\n",
        "\n",
        "            if self.verbose:\n",
        "              print('')\n",
        "              print(method,' of ',c)\n",
        "              print(data_exec_x_copy)\n",
        "            if self.verbose_graph:\n",
        "              data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str(method+' of '+c))\n",
        "\n",
        "            result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "            if self.exec_performance == self.exec_accuracy:\n",
        "              result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "            else:\n",
        "              if self.exec_performance == self.exec_auc:\n",
        "                result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "\n",
        "            str_model_name = 'Clf '+method+' \"'+str(c)+'\"'\n",
        "            self.list_clf_loop.append(str_model_name)\n",
        "            result_bin = compResponses(list(original_outputs), list(result_pred))\n",
        "            result_bin.insert(0,str_model_name)\n",
        "            df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "            df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "\n",
        "      #inset invertion of TWO attributes in loop of models\n",
        "      if self.number_of_features_variation >= 2:\n",
        "        for _,variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              if id2 > id1:\n",
        "                #criando cópia do dado inicial\n",
        "                data_exec_x_copy = data_exec_x.copy()\n",
        "                if variation == self.exec_permutation:\n",
        "                  #trocando posições de cada instância do atributo da vez\n",
        "                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                  data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                  random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                  data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                  method = 'Permutation'\n",
        "                else:\n",
        "                  if variation == self.exec_noise:\n",
        "                    #aplica ruido a cada instâcia do atributo da vez\n",
        "                    noise = np.random.normal(0, 1, number_of_instances)\n",
        "                    data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                    noise = np.random.normal(0, 1, number_of_instances)\n",
        "                    data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                    method = 'Noise'\n",
        "                  else:\n",
        "                    if variation == self.exec_zeros:\n",
        "                      #aplica zeros a cada instância do atributo da vez\n",
        "                      zeros = np.zeros(number_of_instances)\n",
        "                      data_exec_x_copy[c1] = zeros\n",
        "                      data_exec_x_copy[c2] = zeros\n",
        "                      method = 'Zeros'\n",
        "                    else:\n",
        "                      if variation == self.exec_norm:\n",
        "                        #normaliza os elementos\n",
        "                        norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                        normal_array = data_exec_x_copy[c1]/norm\n",
        "                        data_exec_x_copy[c1] = normal_array\n",
        "                        norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                        normal_array = data_exec_x_copy[c2]/norm\n",
        "                        data_exec_x_copy[c2] = normal_array\n",
        "                        method = 'Normalization'\n",
        "                      else:\n",
        "                        if variation == self.exec_ordup:\n",
        "                          #ordena em ordem crescente os elementos\n",
        "                          order_up = np.sort(data_exec_x_copy[c1])\n",
        "                          data_exec_x_copy[c1] = order_up\n",
        "                          order_up = np.sort(data_exec_x_copy[c2])\n",
        "                          data_exec_x_copy[c2] = order_up\n",
        "                          method = 'Ordernation_Up'\n",
        "                        else:\n",
        "                          if variation == self.exec_orddown:\n",
        "                            #ordena em ordem decrescente os elementos\n",
        "                            order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                            data_exec_x_copy[c1] = order_down\n",
        "                            order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                            data_exec_x_copy[c2] = order_down\n",
        "                            method = 'Ordernation_Down'\n",
        "                          else:\n",
        "                            if variation == self.exec_inver:\n",
        "                              #inverte os elementos\n",
        "                              transp = np.flipud(data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = transp\n",
        "                              transp = np.flipud(data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = transp\n",
        "                              method = 'Invertion'\n",
        "                            else:\n",
        "                              if variation == self.exec_binning:\n",
        "                                #inverte os elementos\n",
        "                                mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                data_exec_x_copy[c1] = binn\n",
        "                                mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                data_exec_x_copy[c2] = binn\n",
        "                                method = 'Binning'\n",
        "                              else:\n",
        "                                if variation == self.exec_mult_neg:\n",
        "                                  #multiplica por -1\n",
        "                                  data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                  data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                  method = 'MultNeg'\n",
        "                                else:\n",
        "                                  if variation == self.exec_mean:\n",
        "                                    #mean\n",
        "                                    inst =  len(data_exec_x_copy[c1])\n",
        "                                    data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                    data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                    method = 'Mean'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_std:\n",
        "                                      #std\n",
        "                                      inst =  len(data_exec_x_copy[c1])\n",
        "                                      data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                      data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                      method = 'Std'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_zscore:\n",
        "                                        #zscore\n",
        "                                        data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                        method = 'Zscore'\n",
        "\n",
        "                str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n",
        "                if self.verbose:\n",
        "                  print('')\n",
        "                  print(str_model_name)\n",
        "                  print(data_exec_x_copy)\n",
        "                if self.verbose_graph:\n",
        "                  data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "                #executando o modelo com o atributo da vez embaralhado\n",
        "                result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                if self.exec_performance == self.exec_accuracy:\n",
        "                  result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                else:\n",
        "                  if self.exec_performance == self.exec_auc:\n",
        "                    result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "\n",
        "                str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\"'\n",
        "                self.list_clf_loop.append(str_model_name)\n",
        "                result_bin = compResponses(list(original_outputs), list(result_pred))\n",
        "                result_bin.insert(0,str_model_name)\n",
        "                df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "                df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "              else:\n",
        "                pass\n",
        "\n",
        "      #inset invertion of Three attributes in loop of models\n",
        "      if self.number_of_features_variation >= 3:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              for id3,c3 in enumerate(data_exec_x.columns):\n",
        "                if id3 > id2 and id2 > id1:\n",
        "                  #criando cópia do dado inicial\n",
        "                  data_exec_x_copy = data_exec_x.copy()\n",
        "                  if variation == self.exec_permutation:\n",
        "                    #trocando posições de cada instância do atributo da vez\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                    random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                    data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n",
        "                    method = 'Permutation'\n",
        "                  else:\n",
        "                    if variation == self.exec_noise:\n",
        "                      #aplica ruido a cada instâcia do atributo da vez\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                      noise = np.random.normal(0, 1, number_of_instances)\n",
        "                      data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n",
        "                      method = 'Noise'\n",
        "                    else:\n",
        "                      if variation == self.exec_zeros:\n",
        "                        #aplica zeros a cada instância do atributo da vez\n",
        "                        zeros = np.zeros(number_of_instances)\n",
        "                        data_exec_x_copy[c1] = zeros\n",
        "                        data_exec_x_copy[c2] = zeros\n",
        "                        data_exec_x_copy[c3] = zeros\n",
        "                        method = 'Zeros'\n",
        "                      else:\n",
        "                        if variation == self.exec_norm:\n",
        "                          #normaliza os elementos\n",
        "                          norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                          normal_array = data_exec_x_copy[c1]/norm\n",
        "                          data_exec_x_copy[c1] = normal_array\n",
        "                          norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                          normal_array = data_exec_x_copy[c2]/norm\n",
        "                          data_exec_x_copy[c2] = normal_array\n",
        "                          normal_array = data_exec_x_copy[c3]/norm\n",
        "                          data_exec_x_copy[c3] = normal_array\n",
        "                          method = 'Normalization'\n",
        "                        else:\n",
        "                          if variation == self.exec_ordup:\n",
        "                            #ordena em ordem crescente os elementos\n",
        "                            order_up = np.sort(data_exec_x_copy[c1])\n",
        "                            data_exec_x_copy[c1] = order_up\n",
        "                            order_up = np.sort(data_exec_x_copy[c2])\n",
        "                            data_exec_x_copy[c2] = order_up\n",
        "                            order_up = np.sort(data_exec_x_copy[c3])\n",
        "                            data_exec_x_copy[c3] = order_up\n",
        "                            method = 'Ordernation_Up'\n",
        "                          else:\n",
        "                            if variation == self.exec_orddown:\n",
        "                              #ordena em ordem decrescente os elementos\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = order_down\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = order_down\n",
        "                              order_down = -np.sort(-data_exec_x_copy[c3])\n",
        "                              data_exec_x_copy[c3] = order_down\n",
        "                              method = 'Ordernation_Down'\n",
        "                            else:\n",
        "                              if variation == self.exec_inver:\n",
        "                                #inverte os elementos\n",
        "                                transp = np.flipud(data_exec_x_copy[c1])\n",
        "                                data_exec_x_copy[c1] = transp\n",
        "                                transp = np.flipud(data_exec_x_copy[c2])\n",
        "                                data_exec_x_copy[c2] = transp\n",
        "                                transp = np.flipud(data_exec_x_copy[c3])\n",
        "                                data_exec_x_copy[c3] = transp\n",
        "                                method = 'Invertion'\n",
        "                              else:\n",
        "                                if variation == self.exec_binning:\n",
        "                                  #inverte os elementos\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c1] = binn\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c2] = binn\n",
        "                                  mean_arr = np.mean(data_exec_x_copy[c3])\n",
        "                                  binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n",
        "                                  data_exec_x_copy[c3] = binn\n",
        "                                  method = 'Binning'\n",
        "                                else:\n",
        "                                  if variation == self.exec_mult_neg:\n",
        "                                    #multiplica por -1\n",
        "                                    data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                    data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                    data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n",
        "                                    method = 'MultNeg'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_mean:\n",
        "                                      #mean\n",
        "                                      inst =  len(data_exec_x_copy[c1])\n",
        "                                      data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                      data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                      data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n",
        "                                      method = 'Mean'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_std:\n",
        "                                        #std\n",
        "                                        inst =  len(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                        data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                        data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n",
        "                                        method = 'Std'\n",
        "                                      else:\n",
        "                                        if variation == self.exec_zscore:\n",
        "                                          #zscore\n",
        "                                          data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                          data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                          data_exec_x_copy[c3] = self.z_score_serie(data_exec_x_copy[c3])\n",
        "                                          method = 'Zscore'\n",
        "\n",
        "\n",
        "                  str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\"'\n",
        "                  if self.verbose:\n",
        "                    print('')\n",
        "                    print(str_model_name)\n",
        "                    print(data_exec_x_copy)\n",
        "                  if self.verbose_graph:\n",
        "                    data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "\n",
        "                  result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                  if self.exec_performance == self.exec_accuracy:\n",
        "                    result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                  else:\n",
        "                    if self.exec_performance == self.exec_auc:\n",
        "                      result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "\n",
        "                  self.list_clf_loop.append(str_model_name)\n",
        "                  result_bin = compResponses(list(original_outputs), list(result_pred))\n",
        "                  result_bin.insert(0,str_model_name)\n",
        "                  df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "                  df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "                else:\n",
        "                  pass\n",
        "\n",
        "      #inset invertion of Four attributes in loop of models\n",
        "      if self.number_of_features_variation == 4:\n",
        "        for _, variation in enumerate(self.exec_variation_method):\n",
        "          for id1,c1 in enumerate(data_exec_x.columns):\n",
        "            for id2,c2 in enumerate(data_exec_x.columns):\n",
        "              for id3,c3 in enumerate(data_exec_x.columns):\n",
        "                for id4,c4 in enumerate(data_exec_x.columns):\n",
        "                  if id4 > id3 and id3 > id2 and id2 > id1:\n",
        "                    #criando cópia do dado inicial\n",
        "                    data_exec_x_copy = data_exec_x.copy()\n",
        "                    if variation == self.exec_permutation:\n",
        "                      #trocando posições de cada instância do atributo da vez\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c1] = data_exec_x_copy[c1].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c2] = data_exec_x_copy[c2].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c3] = data_exec_x_copy[c3].values[random_id]\n",
        "                      random_id = random.sample(range(0,number_of_instances), number_of_instances)\n",
        "                      data_exec_x_copy[c4] = data_exec_x_copy[c4].values[random_id]\n",
        "                      method = 'Permutation'\n",
        "                    else:\n",
        "                      if variation == self.exec_noise:\n",
        "                        #aplica ruido a cada instâcia do atributo da vez\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c1] = data_exec_x_copy[c1] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c2] = data_exec_x_copy[c2] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c3] = data_exec_x_copy[c3] + noise\n",
        "                        noise = np.random.normal(0, 1, number_of_instances)\n",
        "                        data_exec_x_copy[c4] = data_exec_x_copy[c4] + noise\n",
        "                        method = 'Noise'\n",
        "                      else:\n",
        "                        if variation == self.exec_zeros:\n",
        "                          #aplica zeros a cada instância do atributo da vez\n",
        "                          zeros = np.zeros(number_of_instances)\n",
        "                          data_exec_x_copy[c1] = zeros\n",
        "                          data_exec_x_copy[c2] = zeros\n",
        "                          data_exec_x_copy[c3] = zeros\n",
        "                          data_exec_x_copy[c4] = zeros\n",
        "                          method = 'Zeros'\n",
        "                        else:\n",
        "                          if variation == self.exec_norm:\n",
        "                            #normaliza os elementos\n",
        "                            norm = np.linalg.norm(data_exec_x_copy[c1])\n",
        "                            normal_array = data_exec_x_copy[c1]/norm\n",
        "                            data_exec_x_copy[c1] = normal_array\n",
        "                            norm = np.linalg.norm(data_exec_x_copy[c2])\n",
        "                            normal_array = data_exec_x_copy[c2]/norm\n",
        "                            data_exec_x_copy[c2] = normal_array\n",
        "                            normal_array = data_exec_x_copy[c3]/norm\n",
        "                            data_exec_x_copy[c3] = normal_array\n",
        "                            normal_array = data_exec_x_copy[c4]/norm\n",
        "                            data_exec_x_copy[c4] = normal_array\n",
        "                            method = 'Normalization'\n",
        "                          else:\n",
        "                            if variation == self.exec_ordup:\n",
        "                              #ordena em ordem crescente os elementos\n",
        "                              order_up = np.sort(data_exec_x_copy[c1])\n",
        "                              data_exec_x_copy[c1] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c2])\n",
        "                              data_exec_x_copy[c2] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c3])\n",
        "                              data_exec_x_copy[c3] = order_up\n",
        "                              order_up = np.sort(data_exec_x_copy[c4])\n",
        "                              data_exec_x_copy[c4] = order_up\n",
        "                              method = 'Ordernation_Up'\n",
        "                            else:\n",
        "                              if variation == self.exec_orddown:\n",
        "                                #ordena em ordem decrescente os elementos\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c1])\n",
        "                                data_exec_x_copy[c1] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c2])\n",
        "                                data_exec_x_copy[c2] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c3])\n",
        "                                data_exec_x_copy[c3] = order_down\n",
        "                                order_down = -np.sort(-data_exec_x_copy[c4])\n",
        "                                data_exec_x_copy[c4] = order_down\n",
        "                                method = 'Ordernation_Down'\n",
        "                              else:\n",
        "                                if variation == self.exec_inver:\n",
        "                                  #inverte os elementos\n",
        "                                  transp = np.flipud(data_exec_x_copy[c1])\n",
        "                                  data_exec_x_copy[c1] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c2])\n",
        "                                  data_exec_x_copy[c2] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c3])\n",
        "                                  data_exec_x_copy[c3] = transp\n",
        "                                  transp = np.flipud(data_exec_x_copy[c4])\n",
        "                                  data_exec_x_copy[c4] = transp\n",
        "                                  method = 'Invertion'\n",
        "                                else:\n",
        "                                  if variation == self.exec_binning:\n",
        "                                    #inverte os elementos\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c1])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c1],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c1] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c2])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c2],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c2] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c3])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c3],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c3] = binn\n",
        "                                    mean_arr = np.mean(data_exec_x_copy[c4])\n",
        "                                    binn = np.digitize(data_exec_x_copy[c4],bins=[mean_arr])\n",
        "                                    data_exec_x_copy[c4] = binn\n",
        "                                    method = 'Binning'\n",
        "                                  else:\n",
        "                                    if variation == self.exec_mult_neg:\n",
        "                                      #multiplica por -1\n",
        "                                      data_exec_x_copy[c1] = data_exec_x_copy[c1] * -1\n",
        "                                      data_exec_x_copy[c2] = data_exec_x_copy[c2] * -1\n",
        "                                      data_exec_x_copy[c3] = data_exec_x_copy[c3] * -1\n",
        "                                      data_exec_x_copy[c4] = data_exec_x_copy[c4] * -1\n",
        "                                      method = 'MultNeg'\n",
        "                                    else:\n",
        "                                      if variation == self.exec_mean:\n",
        "                                        #mean\n",
        "                                        inst =  len(data_exec_x_copy[c1])\n",
        "                                        data_exec_x_copy[c1] = [statistics.mean(data_exec_x_copy[c1])]*inst\n",
        "                                        data_exec_x_copy[c2] = [statistics.mean(data_exec_x_copy[c2])]*inst\n",
        "                                        data_exec_x_copy[c3] = [statistics.mean(data_exec_x_copy[c3])]*inst\n",
        "                                        data_exec_x_copy[c4] = [statistics.mean(data_exec_x_copy[c4])]*inst\n",
        "                                        method = 'Mean'\n",
        "                                      else:\n",
        "                                        if variation == self.exec_std:\n",
        "                                          #std\n",
        "                                          inst =  len(data_exec_x_copy[c1])\n",
        "                                          data_exec_x_copy[c1] = [statistics.stdev(data_exec_x_copy[c1])]*inst\n",
        "                                          data_exec_x_copy[c2] = [statistics.stdev(data_exec_x_copy[c2])]*inst\n",
        "                                          data_exec_x_copy[c3] = [statistics.stdev(data_exec_x_copy[c3])]*inst\n",
        "                                          data_exec_x_copy[c4] = [statistics.stdev(data_exec_x_copy[c4])]*inst\n",
        "                                          method = 'Std'\n",
        "                                        else:\n",
        "                                          if variation == self.exec_zscore:\n",
        "                                            #zscore\n",
        "                                            data_exec_x_copy[c1] = self.z_score_serie(data_exec_x_copy[c1])\n",
        "                                            data_exec_x_copy[c2] = self.z_score_serie(data_exec_x_copy[c2])\n",
        "                                            data_exec_x_copy[c3] = self.z_score_serie(data_exec_x_copy[c3])\n",
        "                                            data_exec_x_copy[c4] = self.z_score_serie(data_exec_x_copy[c4])\n",
        "                                            method = 'Zscore'\n",
        "\n",
        "                    str_model_name = 'Clf '+method+' \"'+str(c1)+'\" and \"'+str(c2)+'\" and \"'+str(c3)+'\" and \"'+str(c4)+'\"'\n",
        "                    if self.verbose:\n",
        "                      print('')\n",
        "                      print(str_model_name)\n",
        "                      print(data_exec_x_copy)\n",
        "                    if self.verbose_graph:\n",
        "                      data_exec_x_copy.plot.kde(by=data_exec_x_copy.columns, alpha=0.5,title=str_model_name)\n",
        "\n",
        "                    result_pred = model.predict(data_exec_x_copy) #prediction\n",
        "\n",
        "                    if self.exec_performance == self.exec_accuracy:\n",
        "                      result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "                    else:\n",
        "                      if self.exec_performance == self.exec_auc:\n",
        "                        result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "\n",
        "                    self.list_clf_loop.append(str_model_name)\n",
        "                    result_bin = compResponses(list(original_outputs), list(result_pred))\n",
        "                    result_bin.insert(0,str_model_name)\n",
        "                    df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "                    df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "                  else:\n",
        "                    pass\n",
        "    else:\n",
        "      if self.exec_proposal == self.proposal_1_pool:\n",
        "\n",
        "        model_copy = copy.deepcopy(model)\n",
        "\n",
        "\n",
        "        if self.include_original_clf_data_pool:\n",
        "          original_outputs = model_copy.predict(X_test)\n",
        "\n",
        "          if self.exec_performance == self.exec_accuracy:\n",
        "            result_accuracy = accuracy_score(y_true = original_outputs, y_pred = original_outputs, normalize=self.normalize_performance) #accuracy\n",
        "          else:\n",
        "            if self.exec_performance == self.exec_auc:\n",
        "              result_accuracy = self.auc_score(original_outputs, original_outputs) #AUC\n",
        "\n",
        "          result_pred = (original_outputs == original_outputs) #binarization\n",
        "\n",
        "\n",
        "          str_model_name = 'Original model'\n",
        "          self.list_clf_pool.append(str_model_name)\n",
        "          temp = result_pred.astype(int)[:].tolist().insert(0,str_model_name) #boolean to int\n",
        "          df_loop_of_models.loc[len(df_loop_of_models)] = temp\n",
        "          df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "          if self.verbose:\n",
        "            print('')\n",
        "            print(str_model_name)\n",
        "            print(X_test)\n",
        "\n",
        "        ps = self.powerSetLimited(data_exec_x.columns, self.number_of_features_deletion) #powerset of all features\n",
        "\n",
        "        for _, ps_c in enumerate(ps):\n",
        "          data_train_x_copy = X_train.copy()\n",
        "          data_test_x_copy = X_test.copy()\n",
        "          for _, c in enumerate(ps_c):\n",
        "            flag_none = True\n",
        "            #remove feature c\n",
        "            data_train_x_copy = data_train_x_copy.drop(c, axis='columns')\n",
        "            data_test_x_copy = data_test_x_copy.drop(c, axis='columns')\n",
        "\n",
        "          if len(data_train_x_copy.columns) == 0:\n",
        "            break\n",
        "\n",
        "          #train new model\n",
        "          model_copy.fit(data_train_x_copy, y_train)\n",
        "\n",
        "          result_pred = model_copy.predict(data_test_x_copy)\n",
        "          if self.exec_performance == self.exec_accuracy:\n",
        "            result_accuracy = accuracy_score(y_true = original_outputs, y_pred = result_pred, normalize=self.normalize_performance) #accuracy\n",
        "          else:\n",
        "            if self.exec_performance == self.exec_auc:\n",
        "              result_accuracy = self.auc_score(original_outputs, result_pred) #AUC\n",
        "\n",
        "\n",
        "\n",
        "          str_model_name = 'Clf feature elimination: '\n",
        "          for _, i in enumerate(ps_c):\n",
        "            str_model_name = str_model_name + '\"'+str(i)+'\" '\n",
        "          self.list_clf_pool.append(str_model_name)\n",
        "          result_bin = compResponses(list(original_outputs), list(result_pred))\n",
        "          result_bin.insert(0,str_model_name)\n",
        "          df_loop_of_models.loc[len(df_loop_of_models)] = result_bin\n",
        "          df_loop_of_models_performance.loc[len(df_loop_of_models_performance)] = [str_model_name, result_accuracy]\n",
        "          if self.verbose:\n",
        "            print('')\n",
        "            print(str_model_name)\n",
        "            print(data_test_x_copy)\n",
        "\n",
        "    df_loop_of_models = df_loop_of_models.set_index('Clf')\n",
        "    if self.verbose:\n",
        "      print('Resume Loop of model')\n",
        "      print(df_loop_of_models)\n",
        "      print()\n",
        "      print('Resume Loop of model accuracy')\n",
        "      print(df_loop_of_models_performance)\n",
        "\n",
        "    df = df_loop_of_models\n",
        "    df.to_csv(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt.csv\")\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt.csv\")\n",
        "\n",
        "    df = df_loop_of_models_performance\n",
        "    df.to_csv(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\",index=False)\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+\"/tabela_base_para_executar_irt_accuracy.csv\")\n",
        "\n",
        "    return  df_loop_of_models, df_loop_of_models_performance\n",
        "\n",
        "  def run_irt(self, datasetName):\n",
        "\n",
        "\n",
        "    %rm -rf $self.path_content$self.path_irt'/irt_item_param.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/irt_item_param_new.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/OutExecution/theta_list.csv'\n",
        "    %rm -rf $self.path_content$self.path_irt'/OutExecution/score_total.csv'\n",
        "\n",
        "    !python decodIRT_MLtIRT.py -dir $self.path_irt -respMatrix $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv'\n",
        "\n",
        "    url = self.path_content+self.path_irt+'/irt_item_param.csv'\n",
        "    result_irt = pd.read_csv(url)\n",
        "    if self.download_files:\n",
        "      files.download(url)\n",
        "\n",
        "    result_irt_new = result_irt.copy()\n",
        "\n",
        "    #save parameters of item by datset\n",
        "    result_irt_dataset = result_irt.copy()\n",
        "    result_irt_dataset.to_csv(self.path_content+self.path_irt+self.path_dataset+'/irt_item_param_'+datasetName+'.csv',index=False)\n",
        "    if self.download_files:\n",
        "      files.download(self.path_content+self.path_irt+self.path_dataset+'/irt_item_param_'+datasetName+'.csv')\n",
        "\n",
        "    if self.irt_divine == False:\n",
        "      result_irt_new['Adivinhacao'] = [0]*len(result_irt_new['Adivinhacao']) #anula os valores de adivinhação\n",
        "    if self.irt_difficulty == False:\n",
        "      result_irt_new['Dificuldade'] = [0]*len(result_irt_new['Dificuldade']) #anula os valores de dificuldade\n",
        "    if self.irt_discriminate == False:\n",
        "      result_irt_new['Discriminacao'] = [0]*len(result_irt_new['Discriminacao']) #anula os valores de Discriminacao\n",
        "\n",
        "    result_irt_new.to_csv(self.path_content+self.path_irt+'/irt_item_param_new.csv',index=False)\n",
        "\n",
        "    !python decodIRT_analysis.py -dir $self.path_irt -nameData OutExecution -respMatrix $self.path_content$self.path_irt'/tabela_base_para_executar_irt.csv' -IRTparam $self.path_content$self.path_irt'/irt_item_param_new.csv' -accur $self.path_content$self.path_irt'/tabela_base_para_executar_irt_accuracy.csv' -scoreAll -save $self.irt_method -missing\n",
        "\n",
        "\n",
        "    %cat IRT_param_freq.txt\n",
        "    %cp IRT_param_freq.txt $self.path_content$self.path_irt$self.path_dataset'/IRT_param_freq_'$datasetName'.txt'\n",
        "    return result_irt_new, result_irt\n",
        "\n",
        "  def run_calc(self, name_of_features_x,datasetName):\n",
        "\n",
        "    if self.exec_base_irt_score == self.exec_theta:\n",
        "      url = self.path_content+self.path_irt+'/OutExecution/theta_list.csv'\n",
        "      name_col = 'Theta'\n",
        "    else:\n",
        "      if self.exec_base_irt_score == self.exec_trueScore:\n",
        "        url = self.path_content+self.path_irt+'/OutExecution/score_total.csv'\n",
        "        name_col = 'Score'\n",
        "\n",
        "    rank_theta = pd.read_csv(url)\n",
        "\n",
        "\n",
        "    if self.download_files:\n",
        "      files.download(url)\n",
        "    rank_theta = rank_theta.sort_values(name_col,ascending=True)\n",
        "\n",
        "    # if exec_proposal == proposal_1_pool:\n",
        "    #   k = number_of_features*number_of_features_deletion*4\n",
        "    # else:\n",
        "    #   if exec_proposal == proposal_2_loop:\n",
        "    #     k = number_of_features*len(exec_variation_method)*number_of_features_variation\n",
        "\n",
        "\n",
        "    #rank_theta.plot.barh(x='Clf',y=name_col,figsize = (15,k),color='green')\n",
        "    rank_theta = rank_theta.set_index(keys='Clf')\n",
        "\n",
        "    if self.exec_proposal == self.proposal_2_loop:\n",
        "      rank_theta_loop = rank_theta.sort_values(by=name_col, ascending=True)\n",
        "\n",
        "      df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n",
        "\n",
        "      for _, feature in enumerate(name_of_features_x):\n",
        "        if self.exec_calc_theta == self.theta_sum:\n",
        "          df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "        else:\n",
        "          if self.exec_calc_theta == self.theta_min:\n",
        "            df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "          else:\n",
        "            if self.exec_calc_theta == self.theta_mean:\n",
        "              df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_loop.filter(like='\"'+feature+'\"', axis='index')[name_col])\n",
        "\n",
        "      df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n",
        "      df_rank_final\n",
        "    else:\n",
        "      if self.exec_proposal == self.proposal_1_pool:\n",
        "\n",
        "        rank_theta_pool = rank_theta.sort_values(by=name_col, ascending=True)\n",
        "\n",
        "        df_rank_final = pd.DataFrame(index=name_of_features_x, columns=[str('Final '+name_col)])\n",
        "\n",
        "        for _, feature in enumerate(name_of_features_x):\n",
        "          if self.exec_calc_theta == self.theta_sum:\n",
        "            df_rank_final.loc[feature,str('Final '+name_col)] = sum(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "          else:\n",
        "            if self.exec_calc_theta == self.theta_min:\n",
        "              df_rank_final.loc[feature,str('Final '+name_col)] = min(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "            else:\n",
        "              if self.exec_calc_theta == self.theta_mean:\n",
        "                df_rank_final.loc[feature,str('Final '+name_col)] = statistics.mean(rank_theta_pool.filter(like=feature, axis='index')[name_col])\n",
        "\n",
        "        df_rank_final = df_rank_final.sort_values(by=str('Final '+name_col), ascending=True)\n",
        "\n",
        "\n",
        "\n",
        "    df_rank_final.to_csv(self.path_content+self.path_irt+self.path_dataset+'/rank_final_'+datasetName+'.csv',index=True)\n",
        "    return df_rank_final\n",
        "\n",
        "  def explainRankByEXirt(self, model, X_train, X_test, y_train, y_test,datasetName):\n",
        "\n",
        "    self.path_dataset = '/'+datasetName\n",
        "    self.dirByDataset(self.path_dataset)\n",
        "\n",
        "    if(self.exec_in == self.exec_test):\n",
        "      data_exec_x = X_test\n",
        "      data_exec_y = y_test\n",
        "    else:\n",
        "      data_exec_x = X_train\n",
        "      data_exec_y = y_train\n",
        "\n",
        "\n",
        "    N = 500\n",
        "    if len(data_exec_y) > N:\n",
        "      data_sample = data_exec_x\n",
        "      data_sample['class'] = data_exec_y\n",
        "\n",
        "      #stratifier sampler\n",
        "      data_sample = data_sample.groupby('class', group_keys=False).apply(lambda x: x.sample(int(np.rint(N*len(x)/len(data_sample))))).sample(frac=1).reset_index(drop=True)\n",
        "\n",
        "      data_exec_y = data_sample['class']\n",
        "      data_sample = data_sample.drop(labels='class', axis=1)\n",
        "      data_exec_x = data_sample\n",
        "\n",
        "    a, b = self.run_prepare(model, data_exec_x, data_exec_y, X_train, X_test, y_train, y_test)\n",
        "\n",
        "    rirt_new, rirt = self.run_irt(datasetName)\n",
        "\n",
        "    rank = self.run_calc(X_train.columns, datasetName)\n",
        "\n",
        "    return list(rank.index), rank"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Load data and Pre-process"
      ],
      "metadata": {
        "id": "nvKrH0aUlvC-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def normalize(df):\n",
        "    # copy the dataframe\n",
        "    df_norm = df.copy()\n",
        "    # apply min-max scaling\n",
        "    for column in df_norm.columns:\n",
        "        if(len(df_norm[column].unique()) > 1): #fix NaN generation\n",
        "          df_norm[column] = (df_norm[column] - df_norm[column].min()) / (df_norm[column].max() - df_norm[column].min())\n",
        "        else:\n",
        "          df_norm[column] = 0\n",
        "    return df_norm"
      ],
      "metadata": {
        "id": "2YGB9snVsqaZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#Select dataset name by openml link https://www.openml.org/search?sort=date\n",
        "dataset_name = \"diabetes\""
      ],
      "metadata": {
        "id": "hSjFdmrjp9ui"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#load dataset by OpenML\n",
        "\n",
        "dataset = openml.datasets.get_dataset(dataset_name)\n",
        "X, Y, categorical_indicator, attribute_names = dataset.get_data(\n",
        "                  dataset_format=\"dataframe\", target=dataset.default_target_attribute)\n",
        "\n",
        "#Preprocess Y and X numerics\n",
        "if (Y.dtype != 'numeric'):\n",
        "  #Y = Y.astype(int)\n",
        "  Y = Y.map({\"tested_positive\":1, \"tested_negative\":0})\n",
        "\n",
        "for i,c in enumerate(X.columns):\n",
        "  if (X[c].dtype != 'float64'):\n",
        "    X[X.select_dtypes(['category']).columns]= X[X.select_dtypes(['category']).columns].apply(lambda x: pd.factorize(x)[0])\n",
        "\n",
        "#Normalization\n",
        "X = normalize(X)\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, Y, test_size=0.3, stratify=Y) # 70% training and 30% test\n"
      ],
      "metadata": {
        "id": "oYts5cLPlzTE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Creation and prediction model"
      ],
      "metadata": {
        "id": "mtvHAgCLtPXm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = RandomForestClassifier(200)\n",
        "model.fit(X_train, y_train)\n",
        "prediction = model.predict(X_test)"
      ],
      "metadata": {
        "id": "MgvqLmsum_nC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Global explanation rank"
      ],
      "metadata": {
        "id": "_NNGxuw4ucIB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "explainer = EXirt()"
      ],
      "metadata": {
        "id": "rhjOukpxtgXE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes, global_explanation_attributes_scores = explainer.explainRankByEXirt(model, X_train, X_test, y_train, y_test,dataset_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 607
        },
        "id": "T8OEPD8bue2F",
        "outputId": "41d26547-0a5a-4063-c06a-f9da7daea535"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "rm: cannot remove '/content/out_irt/tabela_base_para_executar_irt.csv': No such file or directory\n",
            "rm: cannot remove '/content/out_irt/tabela_base_para_executar_irt_accuracy.csv': No such file or directory\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_c91346a9-9ed5-4aa3-8852-08fc996da8f1\", \"tabela_base_para_executar_irt.csv\", 28698)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_eb108c81-9e58-4ca1-b467-5f6952d16f5a\", \"tabela_base_para_executar_irt_accuracy.csv\", 2386)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Calculando os parametros do IRT para o dataset:  /content/out_irt/tabela_base_para_executar_irt.csv\n",
            "R[write to console]: Warning message:\n",
            "\n",
            "R[write to console]: In tpm(read.csv(file = \"tmp_irt_teste.csv\"), IRT.param = TRUE) :\n",
            "R[write to console]: \n",
            " \n",
            "R[write to console]:  Hessian matrix at convergence contains infinite or missing values; unstable solution.\n",
            "\n",
            "\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dca144ce-ef64-4edb-a9ac-07426ff76f1c\", \"irt_item_param.csv\", 5826)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_dd06637b-ddb8-456d-86a2-0d7e4ecd46db\", \"irt_item_param_diabetes.csv\", 5836)"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "As frequencias dos parametros de item foram salvas \\o/\n",
            "\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:2233: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  r = (xf - nfc) * (fx - ffulc)\n",
            "/usr/local/lib/python3.10/dist-packages/scipy/optimize/_optimize.py:2234: RuntimeWarning: invalid value encountered in double_scalars\n",
            "  q = (xf - fulc) * (fx - fnfc)\n",
            "Todos os valores de Theta foram salvos \\o/\n",
            "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n",
            "\n",
            "Os scores dos classificadores para todos os datasets foram salvos \\o/\n",
            "\n",
            "Porcentagem de itens com valores altos do parametro Discriminacao\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                    32%\n",
            "------------------------------------------------------------\n",
            "Porcentagem de itens com valores altos do parametro Dificuldade\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                    17%\n",
            "------------------------------------------------------------\n",
            "Porcentagem de itens com valores altos do parametro Advinhacao\n",
            "Dataset \t\t\t\t Percentual de itens\n",
            "OutExecution                                    13%\n",
            "------------------------------------------------------------\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ],
            "application/javascript": [
              "download(\"download_1324197a-daf5-4a07-a03d-29d7c3f1b0a6\", \"score_total.csv\", 2202)"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pd-KdbaMo4Zy",
        "outputId": "3c778d10-29b3-4d4e-c5b6-e75741f5b688"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['plas', 'mass', 'age', 'pres', 'preg', 'pedi', 'insu', 'skin']"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "global_explanation_attributes_scores"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "g2acOi5QZEz3",
        "outputId": "9833a4fb-3221-424b-f054-7910db1f6020"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Final Score\n",
              "plas   94.859286\n",
              "mass  110.716429\n",
              "age   117.573571\n",
              "pres  127.859286\n",
              "preg  131.287857\n",
              "pedi  134.430714\n",
              "insu  136.002143\n",
              "skin  137.430714"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5df29f75-0b0d-43ef-92e6-389d5059e08e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Final Score</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>plas</th>\n",
              "      <td>94.859286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mass</th>\n",
              "      <td>110.716429</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>age</th>\n",
              "      <td>117.573571</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pres</th>\n",
              "      <td>127.859286</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>preg</th>\n",
              "      <td>131.287857</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>pedi</th>\n",
              "      <td>134.430714</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>insu</th>\n",
              "      <td>136.002143</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>skin</th>\n",
              "      <td>137.430714</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5df29f75-0b0d-43ef-92e6-389d5059e08e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5df29f75-0b0d-43ef-92e6-389d5059e08e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5df29f75-0b0d-43ef-92e6-389d5059e08e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "fYRB58lNnHAX",
        "xQcwXWF97TrR",
        "nvKrH0aUlvC-",
        "mtvHAgCLtPXm",
        "_NNGxuw4ucIB"
      ]
    },
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.4"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}